{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
      "colab": {
        "name": "CNN_voc_2.ipynb",
        "provenance": []
      },
      "kernelspec": {
        "name": "python3",
        "display_name": "Python 3"
      },
      "language_info": {
        "name": "python"
      }
    },
    "cells": [
      {
        "cell_type": "code",
        "execution_count": 1,
        "metadata": {
          "id": "Xvj7hqNscPOr"
        },
        "outputs": [],
        "source": [
          "from glob import glob\n",
          "import cv2\n",
          "import numpy as np\n",
          "import xml.etree.ElementTree as ET\n",
          "import keras\n",
          "from keras import backend as K\n",
          "from tensorflow.keras import optimizers\n",
          "from tensorflow.keras.models import Model\n",
          "from keras.utils import np_utils\n",
          "from keras.preprocessing.image import ImageDataGenerator\n",
          "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
          "from keras.layers import Conv2D, MaxPooling2D\n",
          "from keras import regularizers\n",
          "from keras.callbacks import LearningRateScheduler\n",
          "import matplotlib.pyplot as plt\n",
          "import os\n",
          "import tensorflow.keras.applications as app\n",
          "\n",
          "batch_size = 64\n",
          "n_epochs = 12\n",
          "per_sample_normalization = True\n",
          "data_augmentation = False\n",
          "net_name = [['resnet50','ResNet50'], ['inception_v3','InceptionV3'], ['mobilenet_v2','MobileNetV2']][0]\n",
          "train_from_scratch = True\n",
          "last_layer_activation = ['softmax', 'sigmoid', None][1]\n",
          "loss = ['categorical_crossentropy', 'binary_crossentropy', 'mean_squared_error', 'mean_absolute_error'][1]\n",
          "img_size = 224\n",
          "num_classes = 20\n",
          "voc_classes = {'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, 'bus': 5, 'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, 'diningtable': 10, 'dog': 11, 'horse': 12, 'motorbike': 13, 'person': 14, 'pottedplant': 15, 'sheep': 16, 'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
          "test_imagenet = False\n"
        ]
      },
      {
        "cell_type": "code",
        "source": [
          "# Download and untar voc dataset\n",
          "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
          "!tar xf VOCtrainval_06-Nov-2007.tar\n",
          "print('VOCtrainval_06-Nov-2007.tar has been uncompressed successfully.')"
        ],
        "metadata": {
          "id": "HgZzH6VNc67k"
        },
        "execution_count": null,
        "outputs": []
      },
      {
        "cell_type": "code",
        "source": [
          "# Read and format data\n",
          "def read_content(xml_file: str):\n",
          "    tree = ET.parse(xml_file)\n",
          "    root = tree.getroot()\n",
          "\n",
          "    list_with_all_boxes = []\n",
          "    list_with_all_objects = []\n",
          "    for boxes in root.iter('object'):\n",
          "\n",
          "        classname = boxes.find(\"name\").text\n",
          "        list_with_all_objects.append(voc_classes[classname])\n",
          "\n",
          "        ymin, xmin, ymax, xmax = None, None, None, None\n",
          "\n",
          "        ymin = int(boxes.find(\"bndbox/ymin\").text)\n",
          "        xmin = int(boxes.find(\"bndbox/xmin\").text)\n",
          "        ymax = int(boxes.find(\"bndbox/ymax\").text)\n",
          "        xmax = int(boxes.find(\"bndbox/xmax\").text)\n",
          "\n",
          "        list_with_single_boxes = [xmin, ymin, xmax, ymax]\n",
          "        list_with_all_boxes.append(list_with_single_boxes)\n",
          "\n",
          "    return list_with_all_objects, list_with_all_boxes\n",
          "\n",
          "\n",
          "files = glob('VOCdevkit/VOC2007/JPEGImages/*.jpg')\n",
          "\n",
          "n_samples = len(files)\n",
          "files = files[:n_samples]\n",
          "x_train, y_train, x_test, y_test = [], [], [], []\n",
          "\n",
          "np.random.seed(0)\n",
          "ridx = np.random.randint(0, n_samples, int(n_samples*0.2))\n",
          "train_test_split = np.zeros(n_samples)\n",
          "train_test_split[ridx] = 1\n",
          "for f, i in zip(files, range(n_samples)):\n",
          "    img = cv2.imread(f)\n",
          "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
          "    img = cv2.resize(img, (img_size, img_size))\n",
          "    \n",
          "    if train_test_split[i]:\n",
          "        x_test.append(img)\n",
          "    else:\n",
          "        x_train.append(img)\n",
          "    \n",
          "    classes = np.zeros(num_classes)\n",
          "    root, name = f.split('JPEGImages', 1)\n",
          "    cnames, _ = read_content(root+'Annotations'+name[:-3]+'xml')\n",
          "    for c in cnames:\n",
          "        classes[c] = 1.0\n",
          "            \n",
          "    if train_test_split[i]:\n",
          "        y_test.append(classes)\n",
          "    else:\n",
          "        y_train.append(classes)\n",
          "    \n",
          "x_train = np.array(x_train)\n",
          "y_train = np.array(y_train)\n",
          "x_test = np.array(x_test)\n",
          "y_test = np.array(y_test)"
        ],
        "metadata": {
          "id": "WsAmwaG1c8U8"
        },
        "execution_count": null,
        "outputs": []
      },
      {
        "cell_type": "code",
        "source": [
          "# Test ResNet50 pretrained on imagenet on the voc samples\n",
          "\n",
          "if test_imagenet:\n",
          "  from tensorflow.keras.applications.resnet50 import ResNet50\n",
          "  from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
          "  from copy import copy\n",
          "\n",
          "  model = ResNet50(weights='imagenet')\n",
          "\n",
          "  for x in x_test[:5]:\n",
          "    plt.figure()\n",
          "    plt.imshow(x.astype('uint8'))\n",
          "    plt.show()\n",
          "\n",
          "    x = x[np.newaxis, :, :, :]\n",
          "    px = preprocess_input(copy(x))\n",
          "    \n",
          "    preds = model.predict(px)\n",
          "    \n",
          "    # decode the results into a list of tuples (class, description, probability)\n",
          "    # (one such list for each sample in the batch)\n",
          "    print('Predicted:', decode_predictions(preds, top=3)[0])"
        ],
        "metadata": {
          "id": "r7n_BWIHflB9"
        },
        "execution_count": null,
        "outputs": []
      },
      {
        "cell_type": "code",
        "source": [
          "# Build the model\n",
          "\n",
          "# Select the corresponding network class\n",
          "mynet = getattr(getattr(app, net_name[0]), net_name[1])\n",
          "\n",
          "# create the base pre-trained model\n",
          "if train_from_scratch:\n",
          "  base_model = mynet(include_top=False)\n",
          "else:\n",
          "  base_model = mynet(weights='imagenet', include_top=False)\n",
          "\n",
          "# add a global spatial average pooling layer\n",
          "x = base_model.output\n",
          "x = GlobalAveragePooling2D()(x)\n",
          "# let's add a fully-connected layer\n",
          "x = Dense(1024, activation='relu')(x)\n",
          "# and a logistic layer\n",
          "predictions = Dense(num_classes, activation=last_layer_activation)(x)\n",
          "\n",
          "# this is the model we will train\n",
          "model = Model(inputs=base_model.input, outputs=predictions)"
        ],
        "metadata": {
          "id": "8ej9VbIk_Sfj"
        },
        "execution_count": null,
        "outputs": []
      },
      {
        "cell_type": "code",
        "source": [
          "#training\n",
          "\n",
          "def recall_m(y_true, y_pred):\n",
          "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
          "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
          "    recall = true_positives / (possible_positives + K.epsilon())\n",
          "    return recall\n",
          "\n",
          "def precision_m(y_true, y_pred):\n",
          "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
          "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
          "    precision = true_positives / (predicted_positives + K.epsilon())\n",
          "    return precision\n",
          "\n",
          "def f1_metric(y_true, y_pred):\n",
          "    precision = precision_m(y_true, y_pred)\n",
          "    recall = recall_m(y_true, y_pred)\n",
          "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
          "\n",
          "#data augmentation\n",
          "val_data_gen_args = dict(rescale = None if per_sample_normalization else 1./255,\n",
          "                     samplewise_center=True if per_sample_normalization else False,\n",
          "                     samplewise_std_normalization=True if per_sample_normalization else False)\n",
          "train_data_gen_args = dict(rescale = None if per_sample_normalization else 1./255,\n",
          "                     samplewise_center=True if per_sample_normalization else False,\n",
          "                     samplewise_std_normalization=True if per_sample_normalization else False,\n",
          "                     rotation_range=20,\n",
          "                     width_shift_range=0.1,\n",
          "                     height_shift_range=0.1,\n",
          "                     zoom_range=0.2) if data_augmentation else val_data_gen_args\n",
          "training_datagen = ImageDataGenerator(train_data_gen_args)\n",
          "training_set = training_datagen.flow(x_train, y_train, batch_size=batch_size)\n",
          "val_datagen = ImageDataGenerator(val_data_gen_args)\n",
          "val_set = val_datagen.flow(x_test, y_test, batch_size=batch_size)\n",
          "\n",
          "\n",
          "if train_from_scratch:\n",
          "  opt_rms = optimizers.RMSprop(learning_rate=0.001, decay=1e-6)\n",
          "  model.compile(loss=loss, optimizer=opt_rms, metrics=['AUC', f1_metric])\n",
          "  mdl_fit = model.fit_generator(training_set, steps_per_epoch=x_train.shape[0] // batch_size, \n",
          "                      epochs=n_epochs, verbose=1, validation_data=val_set)\n",
          "else:\n",
          "  # first: train only the top layers (which were randomly initialized)\n",
          "  # i.e. freeze all convolutional layers\n",
          "  for layer in base_model.layers:\n",
          "      layer.trainable = False\n",
          "\n",
          "  # compile the model (should be done *after* setting layers to non-trainable)\n",
          "  opt_rms = optimizers.RMSprop(learning_rate=0.001, decay=1e-6)\n",
          "  model.compile(loss=loss, optimizer=opt_rms, metrics=['AUC', f1_metric])\n",
          "\n",
          "  # train the model on the new data for a few epochs\n",
          "  mdl_fit = model.fit_generator(training_set, steps_per_epoch=x_train.shape[0] // batch_size, \n",
          "                      epochs=5, verbose=1, validation_data=val_set)\n",
          "\n",
          "  # at this point, the top layers are well trained and we can start fine-tuning\n",
          "  # convolutional layers. We will freeze the bottom N layers\n",
          "  # and train the remaining top layers.\n",
          "\n",
          "  # let's visualize layer names and layer indices to see how many layers\n",
          "  # we should freeze:\n",
          "  #for i, layer in enumerate(base_model.layers):\n",
          "  #   print(i, layer.name)\n",
          "\n",
          "  # we unfreeze the layers:\n",
          "  for layer in model.layers:\n",
          "    layer.trainable = True\n",
          "\n",
          "  # we need to recompile the model for these modifications to take effect\n",
          "  # we use SGD with a low learning rate\n",
          "  opt_rms = optimizers.SGD(learning_rate=0.0001, momentum=0.9)\n",
          "  model.compile(loss=loss, optimizer=opt_rms, metrics=['AUC', f1_metric])\n",
          "\n",
          "  # we train our model again (this time fine-tuning the top 2 inception blocks\n",
          "  # alongside the top Dense layers\n",
          "  mdl_fit2 = model.fit_generator(training_set, steps_per_epoch=x_train.shape[0] // batch_size, \n",
          "                      epochs=n_epochs, verbose=1, validation_data=val_set)"
        ],
        "metadata": {
          "id": "z_sLWI2kEJNR"
        },
        "execution_count": null,
        "outputs": []
      }
    ]
  }